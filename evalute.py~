from stable_baselines3 import PPO
from gymnasium.wrappers import FlattenObservation
from GoFishEnv import GoFishEnv  # adjust if your file/module is named differently
import numpy as np

# === Config ===
NUM_GAMES = 100
SHOW_GAME_SUMMARY = True  # Set to False to suppress per-game output

# === Load model ===
model = PPO.load("gofish_ppo_model")

# === Tracking ===
wins = 0
losses = 0
ties = 0

for game in range(NUM_GAMES):
    env = FlattenObservation(GoFishEnv())
    obs, _ = env.reset()
    done = False
    agent_sets = 0
    opponent_sets = 0

    while not done:
        action, _ = model.predict(obs)
        obs, reward, done, _, info = env.step(action)

    # Flattened obs: indices 14 = agent_sets, 15 = opponent_sets (adjust if needed)
    agent_sets = int(obs[14])
    opponent_sets = int(obs[15])

    if agent_sets > opponent_sets:
        wins += 1
        result = "WIN"
    elif agent_sets < opponent_sets:
        losses += 1
        result = "LOSS"
    else:
        ties += 1
        result = "TIE"

    if SHOW_GAME_SUMMARY:
        print(f"Game {game+1}: {result} (Agent: {agent_sets}, Opponent: {opponent_sets})")

# === Final Stats ===
print("\n=== Evaluation Summary ===")
print(f"Total Games: {NUM_GAMES}")
print(f"Wins:   {wins}")
print(f"Losses: {losses}")
print(f"Ties:   {ties}")
print(f"Win Rate: {wins / NUM_GAMES:.2%}")
