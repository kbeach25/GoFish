## Go Fish with RL Agent
This is a program for an online Go Fish game, where a human player plays against a Reinforcement Learning agent. The game state logic and RL agent models were used together with an interactive Streamlit interface to shape a realisitic setting.  

**Link to game:** https://gofishonlinekbeach25.streamlit.app  

## Development
There were three major elements to building this: the Go Fish environment, training and testing the RL agents, and the Streamlit interface.  

The Go Fish environment, GoFishEnv.py, was built using gymnasium to provide the structure and make it compatible with Stable Baselines3, the Reinforcement Learning pipeline used for training the agents. All game logic is handled within this environment, and reward calculation incentivizes intelligent gameplay and penalizes illegal actions and poor strategies. The environment strucutre made implementing it into the Streamlit interface simple.   
The second step was training and testing the RL agents. I had originally trained the agents against a random opponent, which led to very high win rates when I simulated 10,000 games. Despite the win rates, I found that they didn't play too well against me, since I wasn't just picking random cards. So, I made the training opponent more strategic. This led to an overall decrease in win rates, but much more realistic performance when I played agsinst them. I used three scripts for this step: test_agent.py, play_agent.py, and evaluate.py. My test_agent.py script used Proximal Policy Optimization (PPO) from Stable Baselines3 to train agents in my environment. Go Fish is a fairly simple game, so I felt that PPO was a good choice since it handles simple to low complexity tasks well. Agents used for higher difficulties trained with more timesteps. I used play_agent to play against each agent in my terminal, and I made their hand visible to me so I could monitor if they were making intelligent and legal moves. I used evaluate.py to simulate 10,000 games to establish success rates for each model. Each agent played against my heuristic-based opponent, and easy, medium, and hard difficulties achieved win rates of 59.00%, 66.29%, and 74.15% respectively.  
The last step was building and deploying the Streamlit app. My script for this app, app.py, gets a deck of cards from [deckofcardsapi.com ](https://deckofcardsapi.com) and provides a real-time visual of the current game state. It allows you to choose from easy, medium, and hard, and sets the appropriate model depending on the selected difficulty. Once a player has completed 7 sets, the game ends, since it's impossible for the opponent to get more than 6 at that point. You have the option to play again, which takes you back to the landing page and you can choose to play the same difficulty or another one. 
